---
title: Dynamic Kubernetes Cluster Registration
description: Register and unregister Kubernetes clusters without restarting a Teleport Kubernetes Service instance.
version: '13.x'
---

With dynamic Kubernetes cluster registration, you can manage the Kubernetes
clusters connected to your Teleport cluster without needing to modify the
configuration file of an individual Kubernetes Service instance.

Dynamic Kubernetes cluster registration is useful when you have deployed
multiple Kubernetes Service instances or need to regularly reconfigure access to
Kubernetes clusters in your infrastructure.

In this guide, we will show you how to set up dynamic Kubernetes cluster
registration, then create, list, update, and delete Kubernetes clusters via
`tctl`.

## Prerequisites

<Tabs>
  <Tab title="Teleport Community Edition">
    - A running Teleport cluster. For details on how to set this up, see our
      [Getting Started](/docs/ver/13.x/index) guide.

    - The `tctl` admin tool and `tsh` client tool version >= 13.4.16.

      ```code
      $ tctl version
      # Teleport v13.4.16 go1.21

      $ tsh version
      # Teleport v13.4.16 go1.21
      ```

      See [Installation](/docs/ver/13.x/installation) for details.

    To check version information, run the `tctl version` and `tsh version` commands.
    For example:

    ```code
    $ tctl version
    # Teleport v13.4.16 go1.21
      
    $ tsh version
    # Teleport v13.4.16 go1.21
    ```
  </Tab>

  <Tab title="Teleport Team">
    - A Teleport Team account. If you don't have an account, sign
      up to begin your [free trial](https://goteleport.com/signup/).

    - The Enterprise `tctl` admin tool and `tsh` client tool, version >= 14.3.6.

      You can download these tools from the [Cloud Downloads page](/docs/ver/13.x/choose-an-edition/teleport-cloud/downloads).

    To check version information, run the `tctl version` and `tsh version` commands.
    For example:

    ```code
    $ tctl version
    # Teleport Enterprise v14.3.6 go1.21
      
    $ tsh version
    # Teleport v14.3.6 go1.21
    ```
  </Tab>

  <Tab title="Teleport Enterprise">
    - A running Teleport Enterprise cluster. For details on how to set this up, see our Enterprise
      [Getting Started](/docs/ver/13.x/choose-an-edition/teleport-enterprise/introduction) guide.

    - The Enterprise `tctl` admin tool and `tsh` client tool version >=
      13.4.16, which you can download by visiting your [Teleport
      account](https://teleport.sh).

      ```code
      $ tctl version
      # Teleport Enterprise v13.4.16 go1.21

      $ tsh version
      # Teleport v13.4.16 go1.21
      ```
  </Tab>

  <Tab title="Teleport Enterprise Cloud">
    - A Teleport Enterprise Cloud account. If you do not have one, visit the [signup
      page](https://goteleport.com/signup/) to begin a free trial of Teleport Team
      and upgrade to Teleport Enterprise Cloud.

    - The Enterprise `tctl` admin tool and `tsh` client tool version >= 14.3.6.
      You can download these tools from the [Cloud Downloads page](/docs/ver/13.x/choose-an-edition/teleport-cloud/downloads).

      ```code
      $ tctl version
      # Teleport Enterprise v14.3.6 go1.21

      $ tsh version
      # Teleport v14.3.6 go1.21
      ```
  </Tab>
</Tabs>

- A Linux host where you will install the Teleport Kubernetes Service.

  <Tip>
    Our `teleport-kube-agent` Helm chart does not support dynamic Kubernetes
    cluster registration.
  </Tip>

- A Kubernetes cluster to join to your Teleport cluster. You must have
  permissions to create namespaces, secrets, service accounts, cluster roles,
  and cluster role bindings in the cluster.

- Make sure you can connect to your Teleport cluster by authenticating with `tsh`
  so you can execute commands with the `tctl` admin tool:
  <Tabs>
    <Tab title="Self-Hosted">
      ```code
      $ tsh login --proxy=teleport.example.com --user=email@example.com
      $ tctl status
      # Cluster  teleport.example.com
      # Version  13.4.16
      # CA pin   sha256:abdc1245efgh5678abdc1245efgh5678abdc1245efgh5678abdc1245efgh5678
      ```

      You can run subsequent `tctl` commands in this guide on your local machine.

      For full privileges, you can also run `tctl` commands on your Teleport Auth
      Service host.
    </Tab>

    <Tab title="Teleport Cloud">
      ```code
      $ tsh login --proxy=myinstance.teleport.sh --user=email@example.com
      $ tctl status
      # Cluster  myinstance.teleport.sh
      # Version  14.3.6
      # CA pin   sha256:sha-hash-here
      ```

      You must run subsequent `tctl` commands in this guide on your local machine.
    </Tab>
  </Tabs>

## Step 1/3. Set up the Teleport Kubernetes Service

The Teleport Kubernetes Service proxies traffic from Teleport users to a
Kubernetes API server so you can take advantage of passwordless authentication,
role-based access controls, audit logging, and other Teleport features in order
to manage access to Kubernetes.

In this step, you will install the Teleport Kubernetes Service on a Linux host
and configure it to access any Kubernetes cluster you register with your
Teleport cluster.

### Get a join token

Establish trust between your Teleport cluster and your new Kubernetes Service
instance by creating a join token:

```code
$ tctl tokens add --type=kube --ttl=1h --format=text
abcd123-insecure-do-not-use-this
```

Copy the token and keep it somewhere safe so you can use it when running the
Teleport Kubernetes Service.

### Install the Teleport Kubernetes Service

Install the Teleport Kubernetes Service on your Linux host:

Use the appropriate commands for your environment to install your package:

<Tabs dropdownView dropdownCaption="Teleport Edition">
  <Tab title="Teleport Community Edition">
    ```code
    $ curl https://goteleport.com/static/install.sh | bash -s 13.4.16
    ```
  </Tab>

  <Tab title="Teleport Team">
    <Tabs>
      <Tab title="Debian 9+/Ubuntu 16.04+ (apt)">
        Add the Teleport repository to your repository list:

        ```code
        # Download Teleport's PGP public key
        $ sudo curl https://apt.releases.teleport.dev/gpg \
        -o /usr/share/keyrings/teleport-archive-keyring.asc
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport APT repository for cloud.
        $ echo "deb [signed-by=/usr/share/keyrings/teleport-archive-keyring.asc] \
        https://apt.releases.teleport.dev/${ID?} ${VERSION_CODENAME?} stable/cloud" \
        | sudo tee /etc/apt/sources.list.d/teleport.list > /dev/null

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Update the repo and install Teleport and the Teleport updater
        $ sudo apt-get update
        $ sudo apt-get install "teleport-ent=$TELEPORT_VERSION" teleport-ent-updater
        ```
      </Tab>

      <Tab title="Amazon Linux 2/RHEL 7/CentOS 7 (yum)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport YUM repository for cloud.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        $ sudo yum install -y yum-utils
        $ sudo yum-config-manager --add-repo "$(rpm --eval "https://yum.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-yum.repo")"

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Install Teleport and the Teleport updater
        $ sudo yum install "teleport-ent-$TELEPORT_VERSION" teleport-ent-updater

        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```
      </Tab>

      <Tab title="Amazon Linux 2023/RHEL 8+ (dnf)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport YUM repository for cloud.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use the dnf config manager plugin to add the teleport RPM repo
        $ sudo dnf config-manager --add-repo "$(rpm --eval "https://yum.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-yum.repo")"

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Install Teleport and the Teleport updater
        $ sudo dnf install "teleport-ent-$TELEPORT_VERSION" teleport-ent-updater

        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```
      </Tab>

      <Tab title="SLES 12 SP5+ and 15 SP5+ (zypper)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport Zypper repository for cloud.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use Zypper to add the teleport RPM repo
        $ sudo zypper addrepo --refresh --repo $(rpm --eval "https://zypper.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-zypper.repo")

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Install Teleport and the Teleport updater
        $ sudo zypper install "teleport-ent-$TELEPORT_VERSION" teleport-ent-updater
        ```
      </Tab>
    </Tabs>

    ### OS repository channels

    The following channels are available for APT, YUM, and Zypper repos. They may be used in place of
    `stable/v13` anywhere in the Teleport documentation.

    | Channel name     | Description                                                                  |
    | ---------------- | ---------------------------------------------------------------------------- |
    | `stable/<major>` | Receives releases for the specified major release line, i.e. `v13`           |
    | `stable/cloud`   | Rolling channel that receives releases compatible with current Cloud version |
    | `stable/rolling` | Rolling channel that receives all published Teleport releases                |

    <Accordion title="Is my Teleport instance compatible with Teleport Team?">
      Before installing a `teleport` binary with a version besides
      v14, read our compatibility rules to ensure that the
      binary is compatible with Teleport Cloud.

      When running multiple `teleport` binaries within a cluster, the following rules
      apply:

      - **Patch and minor** versions are always compatible, for example, any 8.0.1
        component will work with any 8.0.3 component and any 8.1.0 component will work
        with any 8.3.0 component.
      - Servers support clients that are 1 major version behind, but do not support
        clients that are on a newer major version. For example, an 8.x.x Proxy Service
        is compatible with 7.x.x resource services and 7.x.x `tsh`, but we don't
        guarantee that a 9.x.x resource service will work with an 8.x.x Proxy Service.
        This also means you must not attempt to upgrade from 6.x.x straight to 8.x.x.
        You must upgrade to 7.x.x first.
      - Proxy Services and resource services do not support Auth Services that are on
        an older major version, and will fail to connect to older Auth Services by
        default. This behavior can be overridden by passing `--skip-version-check`
        when starting Proxy Services and resource services.
    </Accordion>
  </Tab>

  <Tab title="Teleport Enterprise">
    <Tabs>
      <Tab title="Debian 9+/Ubuntu 16.04+ (apt)">
        ```code
        # Download Teleport's PGP public key
        $ sudo curl https://apt.releases.teleport.dev/gpg \
        -o /usr/share/keyrings/teleport-archive-keyring.asc
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport APT repository for v13. You'll need to update this
        # file for each major release of Teleport.
        $ echo "deb [signed-by=/usr/share/keyrings/teleport-archive-keyring.asc] \
        https://apt.releases.teleport.dev/${ID?} ${VERSION_CODENAME?} stable/v13" \
        | sudo tee /etc/apt/sources.list.d/teleport.list > /dev/null

        $ sudo apt-get update
        $ sudo apt-get install teleport-ent
        ```

        For FedRAMP/FIPS-compliant installations, install the `teleport-ent-fips` package instead:

        ```code
        $ sudo apt-get install teleport-ent-fips
        ```
      </Tab>

      <Tab title="Amazon Linux 2/RHEL 7 (yum)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport YUM repository for v13. You'll need to update this
        # file for each major release of Teleport.
        # First, get the major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        $ sudo yum install -y yum-utils
        $ sudo yum-config-manager --add-repo "$(rpm --eval "https://yum.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/v13/teleport.repo")"
        $ sudo yum install teleport-ent
        #
        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```

        For FedRAMP/FIPS-compliant installations, install the `teleport-ent-fips` package instead:

        ```code
        $ sudo yum install teleport-ent-fips
        ```
      </Tab>

      <Tab title="Amazon Linux 2/RHEL 7 (zypper)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport Zypper repository for v13. You'll need to update this
        # file for each major release of Teleport.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use zypper to add the teleport RPM repo
        $ sudo zypper addrepo --refresh --repo $(rpm --eval "https://zypper.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-zypper.repo")
        $ sudo yum install teleport-ent
        #
        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```

        For FedRAMP/FIPS-compliant installations, install the `teleport-ent-fips` package instead:

        ```code
        $ sudo yum install teleport-ent-fips
        ```
      </Tab>

      <Tab title="Amazon Linux 2023/RHEL 8+ (dnf)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport YUM repository for v13. You'll need to update this
        # file for each major release of Teleport.
        # First, get the major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use the dnf config manager plugin to add the teleport RPM repo
        $ sudo dnf config-manager --add-repo "$(rpm --eval "https://yum.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/v13/teleport.repo")"

        # Install teleport
        $ sudo dnf install teleport-ent

        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```

        For FedRAMP/FIPS-compliant installations, install the `teleport-ent-fips` package instead:

        ```code
        $ sudo dnf install teleport-ent-fips
        ```
      </Tab>

      <Tab title="SLES 12 SP5+ and 15 SP5+ (zypper)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport Zypper repository.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use Zypper to add the teleport RPM repo
        $ sudo zypper addrepo --refresh --repo $(rpm --eval "https://zypper.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/v13/teleport-zypper.repo")

        # Install teleport
        $ sudo zypper install teleport-ent
        ```

        For FedRAMP/FIPS-compliant installations, install the `teleport-ent-fips` package instead:

        ```code
        $ sudo zypper install teleport-ent-fips
        ```
      </Tab>

      <Tab title="Tarball">
        In the example commands below, update `$SYSTEM_ARCH` with the appropriate
        value (`amd64`, `arm64`, or `arm`). All example commands using this variable
        will update after one is filled out.

        ```code
        $ curl https://cdn.teleport.dev/teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-bin.tar.gz.sha256
        # <checksum> <filename>
        $ curl -O https://cdn.teleport.dev/teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-bin.tar.gz
        $ shasum -a 256 teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-bin.tar.gz
        # Verify that the checksums match
        $ tar -xvf teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-bin.tar.gz
        $ cd teleport-ent
        $ sudo ./install
        ```

        For FedRAMP/FIPS-compliant installations of Teleport Enterprise, package URLs
        will be slightly different:

        ```code
        $ curl https://cdn.teleport.dev/teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-fips-bin.tar.gz.sha256
        # <checksum> <filename>
        $ curl -O https://cdn.teleport.dev/teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-fips-bin.tar.gz
        $ shasum -a 256 teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-fips-bin.tar.gz
        # Verify that the checksums match
        $ tar -xvf teleport-ent-v13.4.16-linux-$SYSTEM_ARCH-fips-bin.tar.gz
        $ cd teleport-ent
        $ sudo ./install
        ```
      </Tab>
    </Tabs>

    ### OS repository channels

    The following channels are available for APT, YUM, and Zypper repos. They may be used in place of
    `stable/v13` anywhere in the Teleport documentation.

    | Channel name     | Description                                                                  |
    | ---------------- | ---------------------------------------------------------------------------- |
    | `stable/<major>` | Receives releases for the specified major release line, i.e. `v13`           |
    | `stable/cloud`   | Rolling channel that receives releases compatible with current Cloud version |
    | `stable/rolling` | Rolling channel that receives all published Teleport releases                |
  </Tab>

  <Tab title="Teleport Enterprise Cloud">
    <Tabs>
      <Tab title="Debian 9+/Ubuntu 16.04+ (apt)">
        Add the Teleport repository to your repository list:

        ```code
        # Download Teleport's PGP public key
        $ sudo curl https://apt.releases.teleport.dev/gpg \
        -o /usr/share/keyrings/teleport-archive-keyring.asc
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport APT repository for cloud.
        $ echo "deb [signed-by=/usr/share/keyrings/teleport-archive-keyring.asc] \
        https://apt.releases.teleport.dev/${ID?} ${VERSION_CODENAME?} stable/cloud" \
        | sudo tee /etc/apt/sources.list.d/teleport.list > /dev/null

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Update the repo and install Teleport and the Teleport updater
        $ sudo apt-get update
        $ sudo apt-get install "teleport-ent=$TELEPORT_VERSION" teleport-ent-updater
        ```
      </Tab>

      <Tab title="Amazon Linux 2/RHEL 7/CentOS 7 (yum)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport YUM repository for cloud.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        $ sudo yum install -y yum-utils
        $ sudo yum-config-manager --add-repo "$(rpm --eval "https://yum.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-yum.repo")"

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Install Teleport and the Teleport updater
        $ sudo yum install "teleport-ent-$TELEPORT_VERSION" teleport-ent-updater

        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```
      </Tab>

      <Tab title="Amazon Linux 2023/RHEL 8+ (dnf)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport YUM repository for cloud.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use the dnf config manager plugin to add the teleport RPM repo
        $ sudo dnf config-manager --add-repo "$(rpm --eval "https://yum.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-yum.repo")"

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Install Teleport and the Teleport updater
        $ sudo dnf install "teleport-ent-$TELEPORT_VERSION" teleport-ent-updater

        # Tip: Add /usr/local/bin to path used by sudo (so 'sudo tctl users add' will work as per the docs)
        # echo "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin" > /etc/sudoers.d/secure_path
        ```
      </Tab>

      <Tab title="SLES 12 SP5+ and 15 SP5+ (zypper)">
        ```code
        # Source variables about OS version
        $ source /etc/os-release
        # Add the Teleport Zypper repository for cloud.
        # First, get the OS major version from $VERSION_ID so this fetches the correct
        # package version.
        $ VERSION_ID=$(echo $VERSION_ID | grep -Eo "^[0-9]+")
        # Use Zypper to add the teleport RPM repo
        $ sudo zypper addrepo --refresh --repo $(rpm --eval "https://zypper.releases.teleport.dev/$ID/$VERSION_ID/Teleport/%{_arch}/stable/cloud/teleport-zypper.repo")

        # Provide your Teleport domain to query the latest compatible Teleport version
        $ export TELEPORT_DOMAIN=example.teleport.com
        $ export TELEPORT_VERSION="$(curl https://$TELEPORT_DOMAIN/v1/webapi/automaticupgrades/channel/default/version | sed 's/v//')"

        # Install Teleport and the Teleport updater
        $ sudo zypper install "teleport-ent-$TELEPORT_VERSION" teleport-ent-updater
        ```
      </Tab>
    </Tabs>

    ### OS repository channels

    The following channels are available for APT, YUM, and Zypper repos. They may be used in place of
    `stable/v13` anywhere in the Teleport documentation.

    | Channel name     | Description                                                                  |
    | ---------------- | ---------------------------------------------------------------------------- |
    | `stable/<major>` | Receives releases for the specified major release line, i.e. `v13`           |
    | `stable/cloud`   | Rolling channel that receives releases compatible with current Cloud version |
    | `stable/rolling` | Rolling channel that receives all published Teleport releases                |

    <Accordion title="Is my Teleport instance compatible with Teleport Enterprise Cloud?">
      Before installing a `teleport` binary with a version besides v14,
      read our compatibility rules to ensure that the binary is compatible with
      Teleport Enterprise Cloud.

      When running multiple `teleport` binaries within a cluster, the following rules
      apply:

      - **Patch and minor** versions are always compatible, for example, any 8.0.1
        component will work with any 8.0.3 component and any 8.1.0 component will work
        with any 8.3.0 component.
      - Servers support clients that are 1 major version behind, but do not support
        clients that are on a newer major version. For example, an 8.x.x Proxy Service
        is compatible with 7.x.x resource services and 7.x.x `tsh`, but we don't
        guarantee that a 9.x.x resource service will work with an 8.x.x Proxy Service.
        This also means you must not attempt to upgrade from 6.x.x straight to 8.x.x.
        You must upgrade to 7.x.x first.
      - Proxy Services and resource services do not support Auth Services that are on
        an older major version, and will fail to connect to older Auth Services by
        default. This behavior can be overridden by passing `--skip-version-check`
        when starting Proxy Services and resource services.
    </Accordion>
  </Tab>
</Tabs>

### Configure the Teleport Kubernetes Service

On the host where you will run the Teleport Kubernetes Service, run the
following command to create a base configuration for your Teleport instance,
assigning `PROXY_SERVICE` to the host and port of your Teleport Proxy Service or
Teleport Cloud tenant and `TOKEN` to the join token we created earlier:

```code
# e.g., teleport.example.com:443
$ PROXY_SERVICE=proxy-addr
# e.g., abcd123-insecure-do-not-use-this;
$ TOKEN=join-token;
$ sudo teleport configure \
--proxy=${PROXY_SERVICE?} \
--roles=kube \
--token=${TOKEN?} \
-o file
```

Edit your configuration file at `/etc/teleport.yaml` to include the following:

```yaml
kubernetes_service:
  enabled: "yes"
  resources:
  - labels:
      "*": "*"
```

This configuration enables your Kubernetes Service instance to connect to any
Kubernetes clusters you register with your Teleport cluster. This is because the
`resources[0].labels` field includes the wildcard pattern (`"*": "*"`), which
allows this Kubernetes Service instance to connect to Kubernetes cluster
resources with any label key or value.

<Accordion title="Selectively watching Kubernetes clusters">
  You can configure a Kubernetes Service instance to watch for a subset of
  Kubernetes clusters by including specific label keys and values instead of
  wildcard characters:

  ```yaml
  resources:
  - labels:
      "env": "prod"
      "region": "us-east-2"
  - labels:
      "env": "test"
      "region": "us-west-1"
  ```

  For the Kubernetes Service to register a cluster, *any* of the items in
  `resources` must match the cluster's labels. For an item in `resources` to
  match, *all* of the `labels` entries within that item must match the cluster's
  labels.

  For example, a cluster with the labels `env:prod` and `region:us-west-1` would
  not match the configuration above, since it only matches the `env:prod` label in
  the first `resources` item and the `region:us-west-1` label in the second
  `resources` item.

  However, a cluster with `env:test` and `region:us-west-1` would match, since it
  matches both labels given in the second `resources` item.

  When you create dynamic Kubernetes cluster resources later in this guide, you
  can assign them labels to ensure that only specific Kubernetes Service instances
  will watch for them.
</Accordion>

### Run the Teleport Kubernetes Service

Configure the Teleport Kubernetes Service to start automatically when the host boots up by
creating a systemd service for it. The instructions depend on how you installed
the Teleport Kubernetes Service.

<Tabs>
  <Tab title="Package Manager">
    On the host where you will run the Teleport Kubernetes Service, enable and start Teleport:

    ```code
    $ sudo systemctl enable teleport
    $ sudo systemctl start teleport
    ```
  </Tab>

  <Tab title="TAR Archive">
    On the host where you will run the Teleport Kubernetes Service, create a systemd service
    configuration for Teleport, enable the Teleport service, and start Teleport:

    ```code
    $ sudo teleport install systemd -o /etc/systemd/system/teleport.service
    $ sudo systemctl enable teleport
    $ sudo systemctl start teleport
    ```
  </Tab>
</Tabs>

You can check the status of the Teleport Kubernetes Service with `systemctl status teleport`
and view its logs with `journalctl -fu teleport`.

## Step 2/3. Authorize your user

To enable dynamic Kubernetes cluster registration in Teleport, you will need to
authorize your user to access the Kubernetes clusters you want to register with
Teleport. We will configure this access in this step, both in Teleport and on
your Kubernetes cluster.

### Allow access to your Kubernetes cluster

Ensure that you are in the correct Kubernetes context for the cluster you would
like to enable access to.

Retrieve all available contexts:

```code
$ kubectl config get-contexts
```

Switch to your context, replacing `CONTEXT_NAME` with the name of your chosen
context:

```code
$ kubectl config use-context CONTEXT_NAME
Switched to context CONTEXT_NAME
```

### Kubernetes authentication

To authenticate to a Kubernetes cluster via Teleport, your Teleport roles must
allow access as at least one Kubernetes user or group. Ensure that you have a
Teleport role that grants access to the cluster you plan to interact with.

Run the following command to get the Kubernetes user for your current context:

```code
$ kubectl config view \
-o jsonpath="{.contexts[?(@.name==\"$(kubectl config current-context)\")].context.user}"
```

Create a file called `kube-access.yaml` with the following content, replacing
`USER` with the output of the command above.

```yaml
kind: role
metadata:
  name: kube-access
version: v6
spec:
  allow:
    kubernetes_labels:
      '*': '*'
    kubernetes_resources:
      - kind: pod
        namespace: "*"
        name: "*"
    kubernetes_groups:
    - viewers
    kubernetes_users:
    # Replace USER with the Kubernetes user for your current context.
    - USER
  deny: {}
```

Apply your changes:

```code
$ tctl create -f kube-access.yaml
```

Assign the `kube-access` role to your Teleport user by running the appropriate
commands for your authentication provider:

<Tabs>
  <Tab title="Local User">
    1. Retrieve your local user's configuration resource:

       ```code
       $ tctl get users/$(tsh status -f json | jq -r '.active.username') > out.yaml
       ```

    2. Edit `out.yaml`, adding `kube-access` to the list of existing roles:

       ```diff
         roles:
          - access
          - auditor
          - editor
       +  - kube-access 
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f out.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>

  <Tab title="GitHub">
    1. Retrieve your `github` authentication connector:

       ```code
       $ tctl get github/github --with-secrets > github.yaml
       ```

       Note that the `--with-secrets` flag adds the value of `spec.signing_key_pair.private_key`
       to the `github.yaml` file. Because this key contains a sensitive value, you should remove the
       github.yaml file immediately after updating the resource.

    2. Edit `github.yaml`, adding `kube-access` to the `teams_to_roles` section.

       The team you should map to this role depends on how you have designed your
       organization's role-based access controls (RBAC). However, the team must include your user account and
       should be the smallest team possible within your organization.

       Here is an example:

       ```diff
         teams_to_roles:
           - organization: octocats
             team: admins
             roles:
               - access
       +       - kube-access
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f github.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>

  <Tab title="SAML">
    1. Retrieve your `saml`  configuration resource:

       ```code
       $ tctl get --with-secrets saml/mysaml > saml.yaml
       ```

       Note that the `--with-secrets` flag adds the value of `spec.signing_key_pair.private_key`
       to the `saml.yaml` file. Because this key contains a sensitive value, you should remove the
       saml.yaml file immediately after updating the resource.

    2. Edit `saml.yaml`, adding `kube-access` to the `attributes_to_roles` section.

       The attribute you should map to this role depends on how you have designed your
       organization's role-based access controls (RBAC). However, the group must include your
       user account and should be the smallest group possible within your organization.

       Here is an example:

       ```diff
         attributes_to_roles:
           - name: "groups"
             value: "my-group"
             roles:
               - access
       +       - kube-access
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f saml.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>

  <Tab title="OIDC">
    1. Retrieve your `oidc`  configuration resource:

       ```code
       $ tctl get oidc/myoidc --with-secrets > oidc.yaml
       ```

       Note that the `--with-secrets` flag adds the value of `spec.signing_key_pair.private_key`
       to the `oidc.yaml` file. Because this key contains a sensitive value, you should remove the
       oidc.yaml file immediately after updating the resource.

    2. Edit `oidc.yaml`, adding `kube-access` to the `claims_to_roles` section.

       The claim you should map to this role depends on how you have designed your organization's
       role-based access controls (RBAC). However, the group must include your user account and
       should be the smallest group possible within your organization.

       Here is an example:

       ```diff
         claims_to_roles:
           - name: "groups"
             value: "my-group"
             roles:
               - access
       +       - kube-access
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f oidc.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>
</Tabs>

Now that Teleport RBAC is configured, you can authenticate to your Kubernetes
cluster via Teleport. To interact with your Kubernetes cluster, you will need to
configure authorization within Kubernetes.

### Kubernetes authorization

To configure authorization within your Kubernetes cluster, you need to create Kubernetes `RoleBinding`s or
`ClusterRoleBindings` that grant permissions to the subjects listed in `kubernetes_users` and
`kubernetes_groups`.

For example, you can grant some limited read-only permissions to the `viewers` group used in the `kube-access`
role defined above:

Create a file called `viewers-bind.yaml` with the following contents:

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: viewers-crb
subjects:
- kind: Group
  # Bind the group "viewers", corresponding to the kubernetes_groups we assigned our "kube-access" role above
  name: viewers
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  # "view" is a default ClusterRole that grants read-only access to resources
  # See: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
  name: view
  apiGroup: rbac.authorization.k8s.io
```

Apply the `ClusterRoleBinding` with `kubectl`:

```code
$ kubectl apply -f viewers-bind.yaml
```

Log out of Teleport and log in again.

### Authorize your user to manage Kubernetes clusters

Teleport tracks Kubernetes clusters in your infrastructure via dynamic
`kube_cluster` resources. To manage access to Kubernetes clusters with Teleport,
your user will need permissions to manage these resources.

In the previous section, you authorized your user to access all Kubernetes
clusters registered in your Teleport cluster. Now that you can access these
clusters, create a role that enables you to manage them.

Create a role definition called `kube-manager.yaml` with the following content:

```yaml
kind: role
metadata:
  name: kube-manager
spec:
  allow:
    rules:
    - resources:
      - kube_cluster
      verbs:
      - list
      - create
      - read
      - update
      - delete
version: v5
```

Create the role:

```code
$ tctl create -f kube-manager.yaml
```

Assign the `kube-manager` role to your Teleport user by running the appropriate
commands for your authentication provider:

<Tabs>
  <Tab title="Local User">
    1. Retrieve your local user's configuration resource:

       ```code
       $ tctl get users/$(tsh status -f json | jq -r '.active.username') > out.yaml
       ```

    2. Edit `out.yaml`, adding `kube-manager` to the list of existing roles:

       ```diff
         roles:
          - access
          - auditor
          - editor
       +  - kube-manager 
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f out.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>

  <Tab title="GitHub">
    1. Retrieve your `github` authentication connector:

       ```code
       $ tctl get github/github --with-secrets > github.yaml
       ```

       Note that the `--with-secrets` flag adds the value of `spec.signing_key_pair.private_key`
       to the `github.yaml` file. Because this key contains a sensitive value, you should remove the
       github.yaml file immediately after updating the resource.

    2. Edit `github.yaml`, adding `kube-manager` to the `teams_to_roles` section.

       The team you should map to this role depends on how you have designed your
       organization's role-based access controls (RBAC). However, the team must include your user account and
       should be the smallest team possible within your organization.

       Here is an example:

       ```diff
         teams_to_roles:
           - organization: octocats
             team: admins
             roles:
               - access
       +       - kube-manager
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f github.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>

  <Tab title="SAML">
    1. Retrieve your `saml`  configuration resource:

       ```code
       $ tctl get --with-secrets saml/mysaml > saml.yaml
       ```

       Note that the `--with-secrets` flag adds the value of `spec.signing_key_pair.private_key`
       to the `saml.yaml` file. Because this key contains a sensitive value, you should remove the
       saml.yaml file immediately after updating the resource.

    2. Edit `saml.yaml`, adding `kube-manager` to the `attributes_to_roles` section.

       The attribute you should map to this role depends on how you have designed your
       organization's role-based access controls (RBAC). However, the group must include your
       user account and should be the smallest group possible within your organization.

       Here is an example:

       ```diff
         attributes_to_roles:
           - name: "groups"
             value: "my-group"
             roles:
               - access
       +       - kube-manager
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f saml.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>

  <Tab title="OIDC">
    1. Retrieve your `oidc`  configuration resource:

       ```code
       $ tctl get oidc/myoidc --with-secrets > oidc.yaml
       ```

       Note that the `--with-secrets` flag adds the value of `spec.signing_key_pair.private_key`
       to the `oidc.yaml` file. Because this key contains a sensitive value, you should remove the
       oidc.yaml file immediately after updating the resource.

    2. Edit `oidc.yaml`, adding `kube-manager` to the `claims_to_roles` section.

       The claim you should map to this role depends on how you have designed your organization's
       role-based access controls (RBAC). However, the group must include your user account and
       should be the smallest group possible within your organization.

       Here is an example:

       ```diff
         claims_to_roles:
           - name: "groups"
             value: "my-group"
             roles:
               - access
       +       - kube-manager
       ```

    3. Apply your changes:

       ```code
       $ tctl create -f oidc.yaml
       ```

    4. Sign out of the Teleport cluster and sign in again to assume the new role.
  </Tab>
</Tabs>

## Step 3/3. Manage dynamic Kubernetes cluster resources

Now that your Teleport user has permissions to manage Kubernetes cluster
resources, we will show you how to create, list, update, and delete them.

### Create a kubeconfig

In this section, you will create a Kubernetes `Config` resource, or kubeconfig,
that your Teleport cluster will use to authenticate to your Kubernetes cluster.

When you signed into Teleport earlier in this guide, `tsh` may have changed your
Kubernetes context to one based on your Teleport cluster, so make sure you
update your Kubernetes context to match the cluster you would like to connect to
Teleport:

```code
$ kubectl config get-contexts
# Assign CONTEXT_NAME to your chosen context
$ kubectl config use-context CONTEXT_NAME
```

On your workstation, download Teleport's `get-kubeconfig.sh` script, which you
will use to generate the kubeconfig:

```code
$ curl -OL \
https://raw.githubusercontent.com/gravitational/teleport/v13.4.16/examples/k8s-auth/get-kubeconfig.sh
```

The script creates a service account for the Teleport Kubernetes Service that
can get Kubernetes pods as well as impersonate users, groups, and other service
accounts. The Teleport Kubernetes Service uses this service account to manage
access to resources in your Kubernetes cluster. The script also ensures that
there is a Kubernetes `Secret` in your cluster to store service account
credentials.

`get-kubeconfig.sh` creates a namespace called `teleport` for the resources it
deploys, though you can choose a different name by assigning the
`TELEPORT_NAMESPACE` environment variable in the shell where you run the script.

After creating resources, `get-kubeconfig.sh` writes a new kubeconfig to a file
called `kubeconfig` in the directory where you run the script.

Run the `get-kubeconfig.sh` script:

```code
$ bash get-kubeconfig.sh
```

The script is successful if you see this message:

```text
Done!
```

Ignore the script's instructions to copy the generated kubeconfig file to the
Teleport Proxy Service. In the next section, we will show you how to use the
kubeconfig file when creating a dynamic `kube_cluster` resource.

### Create a Kubernetes cluster resource

Define a `kube_cluster` resource with the following content in a file called
`kube_cluster.yaml`:

```yaml
kind: kube_cluster
version: v3
metadata:
  name: mycluster
spec:
  kubeconfig: |
```

The `spec.kubeconfig` field in the snippet above begins a multi-line string.
Below, you will include the contents of the kubeconfig file as its value.

Since `spec.kubeconfig` must be a base64-encoded string, convert the kubeconfig
file to base64, then indent it and add it to the `kube_cluster.yaml` resource
definition using the following command:

```code
$ printf "    %s" $(cat kubeconfig | base64) >> kube_cluster.yaml
```

<Accordion title="Add labels to your kube_cluster">
  You can add labels to the `kube_cluster` resource, allowing you to manage access
  to specific clusters from your Teleport roles or Kubernetes Service instances.

  Labels can either be static or dynamic. Static labels are key/value pairs. This
  example defines the `env=prod` and `team=dev` labels:

  ```yaml
  kind: kube_cluster
  version: v3
  metadata:
    name: mycluster
    labels:
      env: prod
      team: dev
  spec:
    kubeconfig: KUBECONFIG
  ```

  You can also add dynamic labels, which define shell commands that a Kubernetes
  Service instance will execute in order to generate labels. To do so, edit the
  `spec.dynamic_labels` field of a `kube_cluster` resource.

  This example runs the `python3 get_region.py` command to fetch the region in
  which the Kubernetes Service is deployed and assign the result to the `region`
  key:

  ```yaml
  kind: kube_cluster
  version: v3
  metadata:
    name: mycluster
  spec:
    kubeconfig: KUBECONFIG
    dynamic_labels:
      region:
        period: "24h"
        command: ["python3", "get_region.py"]
  ```

  When defining a dynamic label, the key within the `spec.dynamic_labels` field
  behaves the same as keys within the `metadata.labels` field, indicating the key
  of the label.

  The Kubernetes Service obtains a value for that key by running the
  command given in `command` every `period`. `command` is an array of strings,
  where the first element indicates the command to execute and each subsequent
  element indicates an argument.

  `period` is a Go duration string, which includes a number and a unit of time.
  Supported units are `ns`, `us` (or `µs`), `ms`, `s`, `m`, and `h`. The example
  above configures the Kubernetes Service to run the command every day.
</Accordion>

To create the `kube_cluster` resource, run the following command:

```code
$ tctl create kube_cluster.yaml
kubernetes cluster "mycluster" has been created
```

### Access your new Kubernetes cluster

Instances of the Teleport Kubernetes Service watch for newly created or updated
`kube_cluster` resources. When you create the `kube_cluster` resource, any
Kubernetes Service instances you have configured to track that cluster's labels
will register that cluster and enable access to it via Teleport.

As a result, you should now see the cluster you registered above when you run
`tsh kube ls`:

```code
$ tsh kube ls
 Kube Cluster Name Labels                      Selected
 ----------------- --------------------------- --------
 mycluster         teleport.dev/origin=dynamic
```

The `teleport.dev/origin=dynamic` label indicates that the cluster was
registered dynamically.

You can also log in to the cluster you just registered:

```code
$ tsh kube login mycluster
Logged into kubernetes cluster "mycluster". Try 'kubectl version' to test the
connection.
```

### List Kubernetes cluster resources

You can list `kube_cluster` resources with the following command:

```code
$ tctl get kube_clusters
```

### Update a Kubernetes cluster resource

To update the `kube_cluster` resource you created earlier, execute the following
command to retrieve the resource as it exists on the Auth Service's backend:

```code
$ tctl get kube_clusters/mycluster > kube_cluster.yaml
```

Edit the `kube_cluster.yaml` file to add a label to your `kube_cluster`:

```diff
  kind: kube_cluster
  metadata:
    id: 9999999999999999999
    labels:
      teleport.dev/origin: dynamic
+     env: test
    name: mycluster
  spec:
    aws: {}
    azure: {}
    kubeconfig: KUBECONFIG
  version: v3
```

Update the resource:

```code
$ tctl create -f kube_cluster.yaml
kubernetes cluster "mycluster" has been updated
```

You should now see the updated labels:

```code
$ tsh kube ls
 Kube Cluster Name Labels                               Selected
 ----------------- ------------------------------------ --------
 mycluster         env=test teleport.dev/origin=dynamic *
```

<Warning>
  If the updated `kube_cluster` resource's labels no longer match the ones a Teleport
  Kubernetes Service instance is configured to watch, the instance will unregister
  and stop proxying the Kubernetes cluster.
</Warning>

### Delete Kubernetes cluster resources

To delete the `kube_cluster` resource you created earlier, run the following
command:

```code
$ tctl rm kube_clusters/mycluster
kubernetes cluster "mycluster" has been deleted
```

This will unregister the Kubernetes cluster from Teleport:

```code
$ tsh kube ls
Kube Cluster Name Labels Selected
----------------- ------ --------
```

## Next steps

In this guide, we showed you how to manage `kube_cluster` resources using
`tctl`. If you are interested in other ways you can manage access to Kubernetes
clusters via Teleport, check out the following guides:

- [Connect a Kubernetes Cluster to Teleport](/docs/ver/13.x/kubernetes-access/getting-started): How to use
  the `teleport-kube-agent` Helm chart to register a Kubernetes cluster with
  Teleport.
- [Kubernetes Access from a Standalone Teleport
  Cluster](/docs/ver/13.x/kubernetes-access/register-clusters/static-kubeconfig): How to use the Teleport Kubernetes
  Service's configuration file to register a Kubernetes cluster with Teleport.
